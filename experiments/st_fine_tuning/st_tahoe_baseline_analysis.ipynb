{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST-Tahoe Baseline Predictions Analysis\n",
    "\n",
    "This notebook analyzes predictions from the pretrained ST-Tahoe model on burn/sham wound healing data.\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "‚ö†Ô∏è **ST-Tahoe was trained on DRUG perturbations** (Basak dataset), not burn injury\n",
    "- Input: 2000 highly variable genes from cell line experiments\n",
    "- Perturbations: Drug treatments (DMSO control)\n",
    "- Task: Drug response prediction\n",
    "\n",
    "üî¨ **Our burn/sham data**:\n",
    "- Input: 2000-dim SE-600M embeddings (truncated from 2058)\n",
    "- Perturbations: Burn vs Sham injury\n",
    "- Task: Wound healing trajectory prediction\n",
    "\n",
    "**Expected result**: ST-Tahoe predictions should NOT meaningfully differentiate burn from sham, as the model was not trained on this biological context. This serves as a **negative control baseline** for comparison with fine-tuned models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Add project root\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ Environment ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load ST-Tahoe Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "pred_path = \"experiments/st_fine_tuning/results/burn_sham_st_tahoe_predictions.h5ad\"\n",
    "\n",
    "if os.path.exists(pred_path):\n",
    "    adata_pred = ad.read_h5ad(pred_path)\n",
    "    print(\"‚úÖ ST-Tahoe predictions loaded\")\n",
    "    print(f\"   Shape: {adata_pred.shape}\")\n",
    "    print(f\"   Predictions: {adata_pred.obsm['X_state_2000'].shape}\")\n",
    "    print(f\"\\n   Conditions: {adata_pred.obs['condition'].value_counts().to_dict()}\")\n",
    "    print(f\"   Timepoints: {adata_pred.obs['timepoint'].value_counts().to_dict()}\")\n",
    "    print(f\"   Cell types: {adata_pred.obs['cell_types_simple_short'].nunique()} types\")\n",
    "else:\n",
    "    print(\"‚ùå Predictions not found!\")\n",
    "    print(f\"   Expected path: {pred_path}\")\n",
    "    print(\"\\n   Run inference first:\")\n",
    "    print(\"   state tx infer --model-dir models/ST-Tahoe ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'adata_pred' in locals():\n",
    "    pred = adata_pred.obsm['X_state_2000']\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"Overall Prediction Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Shape: {pred.shape}\")\n",
    "    print(f\"Range: [{np.min(pred):.4f}, {np.max(pred):.4f}]\")\n",
    "    print(f\"Mean: {np.mean(pred):.4f}\")\n",
    "    print(f\"Std: {np.std(pred):.4f}\")\n",
    "    print(f\"Sparsity: {(pred == 0).sum() / pred.size * 100:.2f}% zeros\")\n",
    "    \n",
    "    # By condition\n",
    "    print(\"\\nBy Condition:\")\n",
    "    print(\"=\" * 60)\n",
    "    for condition in ['Burn', 'Sham']:\n",
    "        mask = adata_pred.obs['condition'] == condition\n",
    "        cond_pred = pred[mask]\n",
    "        print(f\"\\n{condition}:\")\n",
    "        print(f\"  Cells: {mask.sum()}\")\n",
    "        print(f\"  Mean: {np.mean(cond_pred):.4f}\")\n",
    "        print(f\"  Std: {np.std(cond_pred):.4f}\")\n",
    "        print(f\"  Range: [{np.min(cond_pred):.4f}, {np.max(cond_pred):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Burn vs Sham Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'adata_pred' in locals():\n",
    "    burn_mask = adata_pred.obs['condition'] == 'Burn'\n",
    "    sham_mask = adata_pred.obs['condition'] == 'Sham'\n",
    "    \n",
    "    burn_pred = pred[burn_mask]\n",
    "    sham_pred = pred[sham_mask]\n",
    "    \n",
    "    # Distance between conditions\n",
    "    burn_centroid = burn_pred.mean(axis=0)\n",
    "    sham_centroid = sham_pred.mean(axis=0)\n",
    "    between_dist = np.linalg.norm(burn_centroid - sham_centroid)\n",
    "    \n",
    "    # Within-condition distances (as reference)\n",
    "    burn_dists = cdist(burn_pred[:100], [burn_centroid]).mean()\n",
    "    sham_dists = cdist(sham_pred[:100], [sham_centroid]).mean()\n",
    "    within_dist = (burn_dists + sham_dists) / 2\n",
    "    \n",
    "    print(\"Burn vs Sham Separation:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Between-condition distance: {between_dist:.4f}\")\n",
    "    print(f\"Within-condition distance: {within_dist:.4f}\")\n",
    "    print(f\"Separation ratio: {between_dist / within_dist:.4f}\")\n",
    "    print(\"\\n‚ö†Ô∏è  If ratio ‚âà 1.0, burn and sham are NOT differentiated\")\n",
    "    print(\"   (Expected for ST-Tahoe as it wasn't trained on wound healing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'adata_pred' in locals():\n",
    "    # Compute UMAP\n",
    "    sc.pp.neighbors(adata_pred, use_rep='X_state_2000', n_neighbors=15)\n",
    "    sc.tl.umap(adata_pred)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # UMAP by condition\n",
    "    sc.pl.umap(adata_pred, color='condition', ax=axes[0, 0], show=False, title='By Condition')\n",
    "    \n",
    "    # UMAP by timepoint\n",
    "    sc.pl.umap(adata_pred, color='timepoint', ax=axes[0, 1], show=False, title='By Timepoint')\n",
    "    \n",
    "    # UMAP by cell type\n",
    "    sc.pl.umap(adata_pred, color='cell_types_simple_short', ax=axes[0, 2], show=False, title='By Cell Type')\n",
    "    \n",
    "    # Magnitude distribution\n",
    "    magnitudes = np.linalg.norm(pred, axis=1)\n",
    "    burn_mag = magnitudes[burn_mask]\n",
    "    sham_mag = magnitudes[sham_mask]\n",
    "    \n",
    "    axes[1, 0].hist(burn_mag, bins=50, alpha=0.5, label='Burn', color='#E74C3C')\n",
    "    axes[1, 0].hist(sham_mag, bins=50, alpha=0.5, label='Sham', color='#3498DB')\n",
    "    axes[1, 0].set_xlabel('Prediction Magnitude')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].set_title('Prediction Magnitude Distribution')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Mean prediction by cell type\n",
    "    mean_by_celltype = adata_pred.obs.groupby(['cell_types_simple_short', 'condition']).size().unstack(fill_value=0)\n",
    "    mean_by_celltype.plot(kind='bar', ax=axes[1, 1], color=['#E74C3C', '#3498DB'])\n",
    "    axes[1, 1].set_xlabel('Cell Type')\n",
    "    axes[1, 1].set_ylabel('Cell Count')\n",
    "    axes[1, 1].set_title('Cell Type Distribution')\n",
    "    axes[1, 1].legend(title='Condition')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Sparsity\n",
    "    sparsity_burn = (burn_pred == 0).sum(axis=1) / burn_pred.shape[1] * 100\n",
    "    sparsity_sham = (sham_pred == 0).sum(axis=1) / sham_pred.shape[1] * 100\n",
    "    \n",
    "    axes[1, 2].hist(sparsity_burn, bins=50, alpha=0.5, label='Burn', color='#E74C3C')\n",
    "    axes[1, 2].hist(sparsity_sham, bins=50, alpha=0.5, label='Sham', color='#3498DB')\n",
    "    axes[1, 2].set_xlabel('Sparsity (%)')\n",
    "    axes[1, 2].set_ylabel('Count')\n",
    "    axes[1, 2].set_title('Prediction Sparsity')\n",
    "    axes[1, 2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('experiments/st_fine_tuning/results/st_tahoe_baseline_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Visualizations saved to: experiments/st_fine_tuning/results/st_tahoe_baseline_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ST-TAHOE BASELINE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Key Findings:\")\n",
    "if 'adata_pred' in locals():\n",
    "    print(f\"  - Processed {adata_pred.shape[0]:,} cells\")\n",
    "    print(f\"  - Burn cells: {burn_mask.sum():,}\")\n",
    "    print(f\"  - Sham cells: {sham_mask.sum():,}\")\n",
    "    print(f\"  - Burn/Sham separation ratio: {between_dist / within_dist:.3f}\")\n",
    "    print(f\"  - Prediction statistics nearly identical (see above)\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Expected Limitations:\")\n",
    "print(\"  1. ST-Tahoe trained on DRUG perturbations, not burn injury\")\n",
    "print(\"  2. Model uses perturbation vocabulary (drug names), not burn/sham\")\n",
    "print(\"  3. Predictions do NOT capture wound healing biology\")\n",
    "print(\"  4. Burn and Sham predictions are nearly identical\")\n",
    "\n",
    "print(\"\\n‚úÖ Use as Baseline:\")\n",
    "print(\"  - Negative control for comparison\")\n",
    "print(\"  - Fine-tuned models (ST-LoRA variants) should SIGNIFICANTLY outperform\")\n",
    "print(\"  - Expected improvement: higher burn/sham separation, better correlations\")\n",
    "\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "print(\"  1. Train ST-LoRA models (see train_all_st_variants.ipynb)\")\n",
    "print(\"  2. Compare fine-tuned vs baseline (see compare_st_results.ipynb)\")\n",
    "print(\"  3. Validate biological predictions (macrophage polarization, etc.)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}