{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3a: State Transition Data Preparation\n",
    "\n",
    "This notebook prepares the burn/sham wound healing data for State Transition (ST) model training.\n",
    "\n",
    "## Approach: Strategy 2 - Baseline SE-600M + ST Training\n",
    "\n",
    "We will:\n",
    "1. Load baseline SE-600M embeddings\n",
    "2. Validate data format and required columns\n",
    "3. Create TOML configuration for data splits\n",
    "4. Create YAML configuration for ST training\n",
    "5. Validate everything is ready for training\n",
    "\n",
    "**Key Decision**: Using baseline SE-600M embeddings (not LoRA) because cell type preservation is critical for perturbation prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Baseline Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline SE-600M embeddings\n",
    "data_path = \"/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/burn_sham_baseline_embedded.h5ad\"\n",
    "\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "adata = ad.read_h5ad(data_path)\n",
    "\n",
    "print(f\"\\n‚úì Loaded AnnData:\")\n",
    "print(f\"  Shape: {adata.shape[0]} cells x {adata.shape[1]} genes\")\n",
    "print(f\"  Observations: {list(adata.obs.columns)}\")\n",
    "print(f\"  Embeddings: {list(adata.obsm.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate Required Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required columns for ST training\n",
    "required_obs_cols = ['condition', 'timepoint', 'time_days', 'cell_types_simple_short', 'mouse_id']\n",
    "required_obsm_keys = ['X_state']  # Baseline SE-600M embeddings\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VALIDATION: Required Columns\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check observation columns\n",
    "print(\"\\n1. Observation Columns:\")\n",
    "all_valid = True\n",
    "for col in required_obs_cols:\n",
    "    if col in adata.obs.columns:\n",
    "        unique_vals = adata.obs[col].unique()\n",
    "        print(f\"   ‚úì '{col}': {len(unique_vals)} unique values\")\n",
    "        print(f\"      Values: {list(unique_vals)[:10]}...\") if len(unique_vals) > 10 else print(f\"      Values: {list(unique_vals)}\")\n",
    "    else:\n",
    "        print(f\"   ‚úó '{col}': MISSING\")\n",
    "        all_valid = False\n",
    "\n",
    "# Check embedding keys\n",
    "print(\"\\n2. Embedding Keys:\")\n",
    "for key in required_obsm_keys:\n",
    "    if key in adata.obsm:\n",
    "        print(f\"   ‚úì '{key}': shape {adata.obsm[key].shape}\")\n",
    "    else:\n",
    "        print(f\"   ‚úó '{key}': MISSING\")\n",
    "        all_valid = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if all_valid:\n",
    "    print(\"‚úì All required columns present!\")\n",
    "else:\n",
    "    print(\"‚úó Some required columns are missing!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Distribution Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. Condition Distribution:\")\n",
    "print(adata.obs['condition'].value_counts())\n",
    "\n",
    "print(\"\\n2. Timepoint Distribution:\")\n",
    "print(adata.obs['timepoint'].value_counts())\n",
    "\n",
    "print(\"\\n3. Condition √ó Timepoint Distribution:\")\n",
    "cross_tab = pd.crosstab(adata.obs['condition'], adata.obs['timepoint'])\n",
    "print(cross_tab)\n",
    "\n",
    "print(\"\\n4. Cell Type Distribution (top 10):\")\n",
    "print(adata.obs['cell_types_simple_short'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n5. Mouse ID Distribution:\")\n",
    "print(adata.obs['mouse_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Condition distribution\n",
    "adata.obs['condition'].value_counts().plot(kind='bar', ax=axes[0, 0], color=['#FF6B6B', '#4ECDC4'])\n",
    "axes[0, 0].set_title('Condition Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Condition')\n",
    "axes[0, 0].set_ylabel('Number of Cells')\n",
    "\n",
    "# Plot 2: Timepoint distribution\n",
    "adata.obs['timepoint'].value_counts().sort_index().plot(kind='bar', ax=axes[0, 1], color='#95E1D3')\n",
    "axes[0, 1].set_title('Timepoint Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Timepoint')\n",
    "axes[0, 1].set_ylabel('Number of Cells')\n",
    "\n",
    "# Plot 3: Condition √ó Timepoint heatmap\n",
    "import seaborn as sns\n",
    "sns.heatmap(cross_tab, annot=True, fmt='d', cmap='YlOrRd', ax=axes[1, 0], cbar_kws={'label': 'Cell Count'})\n",
    "axes[1, 0].set_title('Condition √ó Timepoint', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 4: Top cell types\n",
    "top_cell_types = adata.obs['cell_types_simple_short'].value_counts().head(8)\n",
    "top_cell_types.plot(kind='barh', ax=axes[1, 1], color='#A8E6CF')\n",
    "axes[1, 1].set_title('Top 8 Cell Types', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Number of Cells')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/st_data_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Saved distribution plot to: figures/st_data_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create TOML Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create examples directory if it doesn't exist\n",
    "os.makedirs('examples', exist_ok=True)\n",
    "\n",
    "# TOML configuration for data splits\n",
    "toml_content = \"\"\"# Burn/Sham Wound Healing Dataset Configuration\n",
    "# For State Transition model training\n",
    "\n",
    "[datasets]\n",
    "burn_sham = \"/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/\"\n",
    "\n",
    "[training]\n",
    "burn_sham = \"train\"\n",
    "\n",
    "# Optional: Hold out specific conditions for zeroshot evaluation\n",
    "# [fewshot]\n",
    "# [fewshot.\"burn_sham.macrophage\"]\n",
    "# val = [\"day19\"]\n",
    "# test = []\n",
    "\"\"\"\n",
    "\n",
    "toml_path = \"examples/burn_sham.toml\"\n",
    "with open(toml_path, 'w') as f:\n",
    "    f.write(toml_content)\n",
    "\n",
    "print(f\"‚úì Created TOML config: {toml_path}\")\n",
    "print(\"\\nContents:\")\n",
    "print(toml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create YAML Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configs directory if it doesn't exist\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "\n",
    "# YAML configuration for ST training\n",
    "config = {\n",
    "    'data': {\n",
    "        'toml_config_path': 'examples/burn_sham.toml',\n",
    "        'embed_key': 'X_state',\n",
    "        'pert_col': 'condition',\n",
    "        'control_pert': 'sham',\n",
    "        'cell_type_key': 'cell_types_simple_short',\n",
    "        'batch_col': 'mouse_id',\n",
    "        'batch_size': 16,\n",
    "        'num_workers': 8,\n",
    "    },\n",
    "    'model': {\n",
    "        'model_class': 'state_transition',\n",
    "        'input_dim': 2048,\n",
    "        'output_dim': 2048,\n",
    "        'hidden_dim': 512,\n",
    "        'cell_set_len': 256,\n",
    "        # Timepoint embedding (requires code modification)\n",
    "        'use_timepoint_embedding': True,\n",
    "        'timepoint_dim': 128,\n",
    "    },\n",
    "    'training': {\n",
    "        'max_steps': 20000,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 0.01,\n",
    "        'warmup_steps': 1000,\n",
    "        'gradient_clip_val': 1.0,\n",
    "        'devices': 2,\n",
    "        'strategy': 'ddp',\n",
    "        'log_every_n_steps': 50,\n",
    "        'val_check_interval': 500,\n",
    "    },\n",
    "    'output': {\n",
    "        'output_dir': '/home/scumpia-mrl/state_models/st_burn_sham',\n",
    "        'experiment_name': 'st_burn_sham_v1',\n",
    "        'save_top_k': 3,\n",
    "        'monitor': 'val_loss',\n",
    "    }\n",
    "}\n",
    "\n",
    "yaml_path = \"configs/state_transition_burn_sham.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"‚úì Created YAML config: {yaml_path}\")\n",
    "print(\"\\nContents:\")\n",
    "print(yaml.dump(config, default_flow_style=False, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"PREPARATION COMPLETE\")\nprint(\"=\" * 80)\n\nprint(\"\\n‚úì Data validated:\")\nprint(f\"   - {adata.n_obs:,} cells\")\nprint(f\"   - {adata.n_vars:,} genes\")\nprint(f\"   - {len(adata.obs['condition'].unique())} conditions: {list(adata.obs['condition'].unique())}\")\nprint(f\"   - {len(adata.obs['timepoint'].unique())} timepoints: {list(adata.obs['timepoint'].unique())}\")\nprint(f\"   - {len(adata.obs['cell_types_simple_short'].unique())} cell types\")\nprint(f\"   - {len(adata.obs['mouse_id'].unique())} mice\")\n\nprint(\"\\n‚úì Configuration files created:\")\nprint(f\"   - TOML: {toml_path}\")\nprint(f\"   - YAML: {yaml_path}\")\n\nprint(\"\\n‚úì Code modifications completed:\")\nprint(\"   - src/state/tx/models/state_transition.py (timepoint embedding added)\")\nprint(\"   Lines 200-210: Added timepoint_encoder initialization\")\nprint(\"   Lines 431-448: Added timepoint embedding in forward pass\")\n\nprint(\"\\nüìã Next Steps:\")\nprint(\"   1. Run phase3b_st_model_training.ipynb to start training\")\nprint(\"\\n   2. Monitor training with TensorBoard:\")\nprint(\"      tensorboard --logdir=/home/scumpia-mrl/state_models/st_burn_sham\")\n\nprint(\"\\n\" + \"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook has prepared all the data and configuration files needed for State Transition model training:\n\n### ‚úÖ Completed\n- Loaded baseline SE-600M embeddings from `burn_sham_baseline_embedded.h5ad`\n- Validated all required columns are present\n- Analyzed data distribution across conditions, timepoints, and cell types\n- Created TOML configuration (`examples/burn_sham.toml`)\n- Created YAML training configuration (`configs/state_transition_burn_sham.yaml`)\n\n### ‚úÖ Code Modifications Completed\nModified Arc Institute's State Transition model to add timepoint embedding support:\n\n**File**: `src/state/tx/models/state_transition.py`\n\n1. **Lines 200-210**: Added timepoint encoder initialization in `__init__`:\n   ```python\n   if kwargs.get(\"use_timepoint_embedding\", False):\n       num_timepoints = kwargs.get(\"num_timepoints\", 3)\n       self.timepoint_encoder = nn.Embedding(\n           num_embeddings=num_timepoints,\n           embedding_dim=hidden_dim,\n       )\n   ```\n\n2. **Lines 431-448**: Added timepoint embedding in forward pass:\n   ```python\n   if self.timepoint_encoder is not None:\n       timepoint_indices = batch.get(\"timepoint_ids\")\n       if timepoint_indices is not None:\n           timepoint_embeddings = self.timepoint_encoder(timepoint_indices.long())\n           seq_input = seq_input + timepoint_embeddings\n   ```\n\n### ‚è≠Ô∏è Next Notebook\nContinue to **phase3b_st_model_training.ipynb** to run the training."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}