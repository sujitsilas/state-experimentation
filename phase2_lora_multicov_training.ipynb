{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: LoRA Multi-Covariate Fine-Tuning of SE-600M\n",
    "\n",
    "This notebook implements parameter-efficient fine-tuning of the STATE SE-600M embedding model using LoRA (Low-Rank Adaptation) adapters with multi-covariate conditioning.\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. **Load Pretrained SE-600M**: Load the 600M parameter transformer model\n",
    "2. **Freeze Base Model**: Keep all pretrained weights frozen\n",
    "3. **Add LoRA Adapters**: Add low-rank trainable adapters to attention layers\n",
    "4. **Add Covariate Encoders**: Create embeddings for timepoint + condition\n",
    "5. **Condition Embeddings**: Combine base embeddings with covariate information\n",
    "6. **Fine-Tune**: Train only LoRA + covariate parameters (~1-5% of total params)\n",
    "\n",
    "## Key Differences from CPA Approach (Previous Incorrect Attempt)\n",
    "\n",
    "- ‚úÖ **LoRA Fine-Tuning**: Works in embedding space, not perturbation prediction space\n",
    "- ‚úÖ **SE-600M**: Modifies the foundation model itself, not a downstream task model\n",
    "- ‚úÖ **Parameter Efficient**: Only trains ~1-5% of parameters vs. training entire CPA model\n",
    "- ‚úÖ **Embedding Conditioning**: Covariates directly influence cell embeddings\n",
    "\n",
    "## Configuration\n",
    "\n",
    "- **Base Model**: SE-600M (600M parameters, 16 transformer layers)\n",
    "- **LoRA Rank**: 16 (low-rank dimension)\n",
    "- **Covariates**: timepoint (3 categories) + condition (2 categories)\n",
    "- **Fusion**: Concatenation + MLP (512 ‚Üí 256 ‚Üí 2048)\n",
    "- **Training**: 2x RTX 5000 Ada, DDP, batch size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load burn/sham dataset\n",
    "data_path = \"/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/burn_sham_data/burn_sham_processed.h5ad\"\n",
    "adata = ad.read_h5ad(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {adata.shape[0]} cells x {adata.shape[1]} genes\")\n",
    "print(f\"\\nObservations (metadata columns): {adata.obs.columns.tolist()}\")\n",
    "print(f\"\\nVariables (gene info): {adata.var.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate covariate columns\n",
    "required_cols = ['condition', 'timepoint', 'cell_types_simple_short', 'mouse_id']\n",
    "\n",
    "for col in required_cols:\n",
    "    if col in adata.obs.columns:\n",
    "        unique_vals = adata.obs[col].unique()\n",
    "        print(f\"‚úì '{col}': {len(unique_vals)} unique values\")\n",
    "        print(f\"  Values: {unique_vals}\")\n",
    "        print(f\"  Distribution:\\n{adata.obs[col].value_counts()}\\n\")\n",
    "    else:\n",
    "        print(f\"‚úó '{col}' NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Condition distribution\n",
    "adata.obs['condition'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Condition Distribution')\n",
    "axes[0].set_xlabel('Condition')\n",
    "axes[0].set_ylabel('Number of Cells')\n",
    "\n",
    "# Timepoint distribution\n",
    "adata.obs['timepoint'].value_counts().plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Timepoint Distribution')\n",
    "axes[1].set_xlabel('Timepoint')\n",
    "axes[1].set_ylabel('Number of Cells')\n",
    "\n",
    "# Cell type distribution\n",
    "cell_type_counts = adata.obs['cell_types_simple_short'].value_counts().head(10)\n",
    "cell_type_counts.plot(kind='barh', ax=axes[2])\n",
    "axes[2].set_title('Top 10 Cell Types')\n",
    "axes[2].set_xlabel('Number of Cells')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LoRA config\n",
    "config_path = \"configs/lora_multicov_config.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize LoRA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.state.emb.nn.lora_covariate_model import LoRACovariateStateModel\n",
    "\n",
    "# Initialize model\n",
    "print(\"Loading LoRA model...\")\n",
    "model = LoRACovariateStateModel(\n",
    "    base_checkpoint_path=config['base_checkpoint'],\n",
    "    covariate_config=config['covariates'],\n",
    "    lora_config=config['lora'],\n",
    "    learning_rate=config['training']['learning_rate'],\n",
    "    warmup_steps=config['training']['warmup_steps'],\n",
    ")\n",
    "\n",
    "# Print trainable parameters\n",
    "print(\"\\nTrainable Parameters:\")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Architecture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LoRA Multi-Covariate Model Architecture\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. BASE MODEL (Frozen):\")\n",
    "print(f\"   - SE-600M Transformer: 16 layers, 16 heads, 2048 hidden dim\")\n",
    "print(f\"   - Token Encoder: Linear(5120 ‚Üí 2048) + LayerNorm + SiLU\")\n",
    "print(f\"   - Transformer Encoder: 16x FlashTransformerEncoderLayer\")\n",
    "print(f\"   - Decoder: SkipBlock + Linear(2048 ‚Üí 2048)\")\n",
    "print(f\"   - Status: ‚ùÑÔ∏è FROZEN (all 600M parameters)\")\n",
    "\n",
    "print(\"\\n2. LoRA ADAPTERS (Trainable):\")\n",
    "print(f\"   - Target: Attention Q, V projections\")\n",
    "print(f\"   - Rank: {config['lora']['r']}\")\n",
    "print(f\"   - Alpha: {config['lora']['lora_alpha']}\")\n",
    "print(f\"   - Dropout: {config['lora']['lora_dropout']}\")\n",
    "print(f\"   - Applied to: {len(config['lora']['target_modules'])} projection types √ó 16 layers\")\n",
    "\n",
    "print(\"\\n3. COVARIATE ENCODER (Trainable):\")\n",
    "for cov in config['covariates']['covariates']:\n",
    "    print(f\"   - {cov['name']}: {cov['type']} ({cov.get('num_categories', 'N/A')} categories) ‚Üí {cov.get('embed_dim', 'N/A')} dim\")\n",
    "print(f\"   - Combination MLP: {config['covariates']['combination']['mlp_hidden_dims']} ‚Üí {config['covariates']['combination']['mlp_output_dim']}\")\n",
    "\n",
    "print(\"\\n4. CONDITIONING PROJECTION (Trainable):\")\n",
    "print(f\"   - Input: Concat(base_embedding, covariate_embedding) = 4096 dim\")\n",
    "print(f\"   - Output: Conditioned embedding = 2048 dim\")\n",
    "print(f\"   - Architecture: Linear + LayerNorm + SiLU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Training is resource-intensive and should be run via the training script\n",
    "# This notebook demonstrates the setup and validation\n",
    "\n",
    "print(\"To start training, run:\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"python train_lora_multicov.py --config configs/lora_multicov_config.yaml\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nExpected training time: 4-6 hours on 2x RTX 5000 Ada\")\n",
    "print(\"\\nMonitor training with TensorBoard:\")\n",
    "print(\"tensorboard --logdir=/home/scumpia-mrl/state_models/burn_sham_lora_multicov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Trained Model (After Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best trained checkpoint (lowest validation loss)\n",
    "checkpoint_path = \"/home/scumpia-mrl/state_models/burn_sham_lora_multicov/checkpoints/epoch=09-val_loss=0.5877.ckpt\"\n",
    "\n",
    "print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "trained_model = LoRACovariateStateModel.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    base_checkpoint_path=config['base_checkpoint'],\n",
    "    covariate_config=config['covariates'],\n",
    "    lora_config=config['lora'],\n",
    ")\n",
    "trained_model.eval()\n",
    "trained_model = trained_model.cuda()  # Move to GPU for faster inference\n",
    "\n",
    "print(\"\\n‚úì Trained model loaded successfully!\")\n",
    "print(f\"  Model device: {next(trained_model.parameters()).device}\")\n",
    "print(f\"  Validation loss: 0.5877\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract Covariate-Conditioned Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if embeddings exist and verify which checkpoint was used\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "embeddings_path = \"/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/burn_sham_lora_embedded.h5ad\"\n",
    "best_checkpoint_path = \"/home/scumpia-mrl/state_models/burn_sham_lora_multicov/checkpoints/epoch=09-val_loss=0.5877.ckpt\"\n",
    "\n",
    "if os.path.exists(embeddings_path):\n",
    "    # Check timestamps\n",
    "    emb_time = datetime.fromtimestamp(os.path.getmtime(embeddings_path))\n",
    "    ckpt_time = datetime.fromtimestamp(os.path.getmtime(best_checkpoint_path))\n",
    "    \n",
    "    print(f\"Embeddings file: {embeddings_path}\")\n",
    "    print(f\"  Created: {emb_time}\")\n",
    "    print(f\"\\nBest checkpoint: {best_checkpoint_path}\")\n",
    "    print(f\"  Created: {ckpt_time}\")\n",
    "    print(f\"\\n‚ö† Embeddings were created {(emb_time - ckpt_time).days} days AFTER best checkpoint\")\n",
    "    print(f\"‚ö† This suggests embeddings may be from the best checkpoint!\")\n",
    "    \n",
    "    # Load and verify\n",
    "    print(f\"\\nLoading embeddings file to verify...\")\n",
    "    adata = ad.read_h5ad(embeddings_path)\n",
    "    \n",
    "    print(f\"\\n‚úì Loaded AnnData:\")\n",
    "    print(f\"  Shape: {adata.shape}\")\n",
    "    print(f\"  Embeddings in .obsm: {list(adata.obsm.keys())}\")\n",
    "    \n",
    "    if 'X_lora_conditioned' in adata.obsm:\n",
    "        print(f\"\\n‚úì Found 'X_lora_conditioned': {adata.obsm['X_lora_conditioned'].shape}\")\n",
    "        print(f\"\\nEmbeddings appear to exist. Proceeding with visualization and analysis...\")\n",
    "    else:\n",
    "        print(\"\\n‚úó No 'X_lora_conditioned' found.\")\n",
    "        print(\"Need to extract embeddings from best checkpoint.\")\n",
    "        \n",
    "        # Offer to run extraction\n",
    "        print(\"\\nTo extract embeddings from best checkpoint, run:\")\n",
    "        print(f\"python extract_embeddings.py --config configs/lora_multicov_config.yaml --checkpoint {best_checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"‚úó Embeddings file not found: {embeddings_path}\")\n",
    "    print(\"\\nNeed to extract embeddings from checkpoint.\")\n",
    "    print(f\"\\nRun:\")\n",
    "    print(f\"python extract_embeddings.py --config configs/lora_multicov_config.yaml --checkpoint {best_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate UMAP visualization with LoRA-conditioned embeddings\n",
    "if 'X_lora_conditioned' not in adata.obsm:\n",
    "    print(\"ERROR: No LoRA conditioned embeddings found!\")\n",
    "    print(\"Please run the embedding extraction first.\")\n",
    "else:\n",
    "    print(\"Computing UMAP on LoRA-conditioned embeddings...\")\n",
    "    \n",
    "    # Compute neighbors and UMAP\n",
    "    sc.pp.neighbors(adata, use_rep='X_lora_conditioned', n_neighbors=15, random_state=42)\n",
    "    sc.tl.umap(adata, random_state=42)\n",
    "    \n",
    "    print(\"‚úì UMAP computed successfully!\")\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Timepoint\n",
    "    sc.pl.umap(adata, color='timepoint', ax=axes[0, 0], show=False, title='LoRA Embeddings: Timepoint')\n",
    "    \n",
    "    # Plot 2: Condition\n",
    "    sc.pl.umap(adata, color='condition', ax=axes[0, 1], show=False, title='LoRA Embeddings: Condition')\n",
    "    \n",
    "    # Plot 3: Cell Type\n",
    "    sc.pl.umap(adata, color='cell_types_simple_short', ax=axes[0, 2], show=False, \n",
    "               title='LoRA Embeddings: Cell Type', legend_loc='on data', legend_fontsize=6)\n",
    "    \n",
    "    # Plot 4: Mouse ID\n",
    "    sc.pl.umap(adata, color='mouse_id', ax=axes[1, 0], show=False, title='LoRA Embeddings: Mouse ID')\n",
    "    \n",
    "    # Plot 5: Combined (timepoint + condition)\n",
    "    adata.obs['timepoint_condition'] = adata.obs['timepoint'].astype(str) + '_' + adata.obs['condition'].astype(str)\n",
    "    sc.pl.umap(adata, color='timepoint_condition', ax=axes[1, 1], show=False, \n",
    "               title='LoRA Embeddings: Timepoint √ó Condition')\n",
    "    \n",
    "    # Plot 6: Number of genes detected\n",
    "    if 'n_genes' not in adata.obs.columns:\n",
    "        adata.obs['n_genes'] = (adata.X > 0).sum(axis=1).A1 if hasattr((adata.X > 0).sum(axis=1), 'A1') else (adata.X > 0).sum(axis=1)\n",
    "    sc.pl.umap(adata, color='n_genes', ax=axes[1, 2], show=False, \n",
    "               title='LoRA Embeddings: Gene Count', cmap='viridis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/lora_embeddings_umap_overview.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úì UMAP visualization saved to: lora_embeddings_umap_overview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative evaluation: Compare baseline vs LoRA embeddings\n",
    "if 'adata_baseline' in locals() and baseline_key is not None:\n",
    "    # Compute evaluation metrics\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    from scipy.spatial.distance import cdist\n",
    "    \n",
    "    def evaluate_embeddings(adata_eval, embedding_key, name):\n",
    "        \"\"\"Evaluate embedding quality using multiple metrics.\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Evaluating: {name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X = adata_eval.obsm[embedding_key]\n",
    "        \n",
    "        # 1. Cell Type Classification (kNN)\n",
    "        print(\"\\n1. Cell Type Classification (10-fold CV):\")\n",
    "        y = adata_eval.obs['cell_types_simple_short'].values\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        for seed in range(10):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "            )\n",
    "            knn = KNeighborsClassifier(n_neighbors=15)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            \n",
    "            accuracies.append(accuracy_score(y_test, y_pred))\n",
    "            f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "        \n",
    "        print(f\"   Accuracy: {np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}\")\n",
    "        print(f\"   F1 Score: {np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\")\n",
    "        \n",
    "        # 2. Temporal Coherence\n",
    "        print(\"\\n2. Temporal Coherence (lower = more coherent):\")\n",
    "        timepoints = sorted(adata_eval.obs['timepoint'].unique())\n",
    "        \n",
    "        temporal_distances = []\n",
    "        for i in range(len(timepoints) - 1):\n",
    "            tp1, tp2 = timepoints[i], timepoints[i+1]\n",
    "            \n",
    "            # Get embeddings for each timepoint\n",
    "            idx1 = adata_eval.obs['timepoint'] == tp1\n",
    "            idx2 = adata_eval.obs['timepoint'] == tp2\n",
    "            \n",
    "            emb1 = X[idx1]\n",
    "            emb2 = X[idx2]\n",
    "            \n",
    "            # Compute average distance between consecutive timepoints\n",
    "            distances = cdist(emb1, emb2, metric='cosine')\n",
    "            avg_dist = np.mean(distances)\n",
    "            temporal_distances.append(avg_dist)\n",
    "            \n",
    "            print(f\"   {tp1} ‚Üí {tp2}: {avg_dist:.4f}\")\n",
    "        \n",
    "        avg_temporal_coherence = np.mean(temporal_distances)\n",
    "        print(f\"   Average: {avg_temporal_coherence:.4f}\")\n",
    "        \n",
    "        # 3. Condition Separation\n",
    "        print(\"\\n3. Condition Separation (higher = better separation):\")\n",
    "        condition_separations = []\n",
    "        \n",
    "        for tp in timepoints:\n",
    "            tp_mask = adata_eval.obs['timepoint'] == tp\n",
    "            \n",
    "            burn_emb = X[(tp_mask) & (adata_eval.obs['condition'] == 'burn')]\n",
    "            sham_emb = X[(tp_mask) & (adata_eval.obs['condition'] == 'sham')]\n",
    "            \n",
    "            if len(burn_emb) > 0 and len(sham_emb) > 0:\n",
    "                # Average distance between burn and sham at this timepoint\n",
    "                distances = cdist(burn_emb, sham_emb, metric='cosine')\n",
    "                avg_dist = np.mean(distances)\n",
    "                condition_separations.append(avg_dist)\n",
    "                print(f\"   {tp}: burn ‚Üî sham distance = {avg_dist:.4f}\")\n",
    "        \n",
    "        avg_condition_separation = np.mean(condition_separations)\n",
    "        print(f\"   Average: {avg_condition_separation:.4f}\")\n",
    "        \n",
    "        # 4. Batch Mixing (Silhouette score)\n",
    "        print(\"\\n4. Batch Mixing - Mouse ID (lower = better mixing):\")\n",
    "        from sklearn.metrics import silhouette_score\n",
    "        \n",
    "        if 'mouse_id' in adata_eval.obs.columns:\n",
    "            # Sample for speed\n",
    "            sample_size = min(5000, len(X))\n",
    "            sample_idx = np.random.choice(len(X), sample_size, replace=False)\n",
    "            sil_score = silhouette_score(X[sample_idx], adata_eval.obs['mouse_id'].iloc[sample_idx], \n",
    "                                        metric='cosine')\n",
    "            print(f\"   Silhouette Score: {sil_score:.4f}\")\n",
    "        else:\n",
    "            sil_score = np.nan\n",
    "        \n",
    "        return {\n",
    "            'name': name,\n",
    "            'accuracy': np.mean(accuracies),\n",
    "            'accuracy_std': np.std(accuracies),\n",
    "            'f1_score': np.mean(f1_scores),\n",
    "            'f1_std': np.std(f1_scores),\n",
    "            'temporal_coherence': avg_temporal_coherence,\n",
    "            'condition_separation': avg_condition_separation,\n",
    "            'batch_silhouette': sil_score\n",
    "        }\n",
    "    \n",
    "    # Evaluate both embeddings\n",
    "    baseline_metrics = evaluate_embeddings(adata_baseline, baseline_key, 'Baseline SE-600M')\n",
    "    lora_metrics = evaluate_embeddings(adata, 'X_lora_conditioned', 'LoRA Multi-Covariate')\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_df = pd.DataFrame([baseline_metrics, lora_metrics])\n",
    "    comparison_df = comparison_df.set_index('name')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY: Baseline vs LoRA Multi-Covariate\")\n",
    "    print(\"=\"*80)\n",
    "    print(comparison_df[['accuracy', 'f1_score', 'temporal_coherence', 'condition_separation', 'batch_silhouette']])\n",
    "    \n",
    "    # Compute improvement\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"IMPROVEMENT (LoRA vs Baseline)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    improvements = {\n",
    "        'Accuracy': ((lora_metrics['accuracy'] - baseline_metrics['accuracy']) / baseline_metrics['accuracy']) * 100,\n",
    "        'F1 Score': ((lora_metrics['f1_score'] - baseline_metrics['f1_score']) / baseline_metrics['f1_score']) * 100,\n",
    "        'Temporal Coherence': ((baseline_metrics['temporal_coherence'] - lora_metrics['temporal_coherence']) / baseline_metrics['temporal_coherence']) * 100,  # Lower is better\n",
    "        'Condition Separation': ((lora_metrics['condition_separation'] - baseline_metrics['condition_separation']) / baseline_metrics['condition_separation']) * 100,\n",
    "        'Batch Mixing': ((baseline_metrics['batch_silhouette'] - lora_metrics['batch_silhouette']) / abs(baseline_metrics['batch_silhouette'])) * 100,  # Lower is better\n",
    "    }\n",
    "    \n",
    "    for metric, value in improvements.items():\n",
    "        print(f\"{metric:25s}: {value:+.2f}%\")\n",
    "    \n",
    "    # Save metrics\n",
    "    comparison_df.to_csv('/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/lora_vs_baseline_metrics.csv')\n",
    "    print(\"\\n‚úì Metrics saved to: lora_vs_baseline_metrics.csv\")\n",
    "else:\n",
    "    print(\"Skipping quantitative evaluation (baseline data not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison: Baseline vs LoRA UMAPs\n",
    "if 'adata_baseline' in locals() and baseline_key is not None:\n",
    "    print(\"Computing UMAP for baseline embeddings...\")\n",
    "    \n",
    "    # Compute UMAP for baseline\n",
    "    sc.pp.neighbors(adata_baseline, use_rep=baseline_key, n_neighbors=15, random_state=42)\n",
    "    sc.tl.umap(adata_baseline, random_state=42)\n",
    "    \n",
    "    # Create comparison figure\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Row 1: Baseline embeddings\n",
    "    sc.pl.umap(adata_baseline, color='timepoint', ax=axes[0, 0], show=False, \n",
    "               title='Baseline SE-600M: Timepoint')\n",
    "    sc.pl.umap(adata_baseline, color='condition', ax=axes[0, 1], show=False, \n",
    "               title='Baseline SE-600M: Condition')\n",
    "    sc.pl.umap(adata_baseline, color='cell_types_simple_short', ax=axes[0, 2], show=False, \n",
    "               title='Baseline SE-600M: Cell Type', legend_loc='on data', legend_fontsize=6)\n",
    "    \n",
    "    # Row 2: LoRA embeddings (recompute UMAP for consistency)\n",
    "    sc.pp.neighbors(adata, use_rep='X_lora_conditioned', n_neighbors=15, random_state=42)\n",
    "    sc.tl.umap(adata, random_state=42)\n",
    "    \n",
    "    sc.pl.umap(adata, color='timepoint', ax=axes[1, 0], show=False, \n",
    "               title='LoRA Multi-Cov: Timepoint')\n",
    "    sc.pl.umap(adata, color='condition', ax=axes[1, 1], show=False, \n",
    "               title='LoRA Multi-Cov: Condition')\n",
    "    sc.pl.umap(adata, color='cell_types_simple_short', ax=axes[1, 2], show=False, \n",
    "               title='LoRA Multi-Cov: Cell Type', legend_loc='on data', legend_fontsize=6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/baseline_vs_lora_comparison.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úì Comparison plot saved to: baseline_vs_lora_comparison.png\")\n",
    "else:\n",
    "    print(\"Skipping baseline comparison (baseline data not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline embeddings for comparison\n",
    "baseline_path = \"/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/burn_sham_baseline_embedded.h5ad\"\n",
    "\n",
    "if os.path.exists(baseline_path):\n",
    "    print(f\"Loading baseline embeddings from: {baseline_path}\")\n",
    "    adata_baseline = ad.read_h5ad(baseline_path)\n",
    "    \n",
    "    print(f\"‚úì Baseline data loaded: {adata_baseline.shape}\")\n",
    "    print(f\"  Embeddings in .obsm: {list(adata_baseline.obsm.keys())}\")\n",
    "    \n",
    "    # Check for baseline embedding key\n",
    "    baseline_key = None\n",
    "    for key in ['X_state', 'X_state_baseline', 'X_emb']:\n",
    "        if key in adata_baseline.obsm:\n",
    "            baseline_key = key\n",
    "            print(f\"\\n‚úì Using baseline embeddings: '{baseline_key}' {adata_baseline.obsm[baseline_key].shape}\")\n",
    "            break\n",
    "    \n",
    "    if baseline_key is None:\n",
    "        print(\"\\n‚ö† No baseline embeddings found in standard keys\")\n",
    "else:\n",
    "    print(f\"‚ö† Baseline embeddings file not found at: {baseline_path}\")\n",
    "    print(\"Will skip baseline comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save AnnData with both baseline and LoRA embeddings\n",
    "output_path = \"/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/burn_sham_data/burn_sham_with_lora_embeddings.h5ad\"\n",
    "\n",
    "# Copy UMAP coordinates to obsm\n",
    "adata.obsm['X_umap_lora'] = adata.obsm['X_umap'].copy()\n",
    "adata_baseline.obsm['X_umap_baseline'] = adata_baseline.obsm['X_umap'].copy()\n",
    "\n",
    "# Merge baseline UMAP into main adata\n",
    "adata.obsm['X_umap_baseline'] = adata_baseline.obsm['X_umap_baseline']\n",
    "\n",
    "# Save\n",
    "adata.write_h5ad(output_path)\n",
    "print(f\"‚úì Saved AnnData with embeddings to: {output_path}\")\n",
    "print(f\"\\nEmbeddings in adata.obsm:\")\n",
    "for key in adata.obsm.keys():\n",
    "    print(f\"  - {key}: {adata.obsm[key].shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  1. lora_embeddings_umap_overview.png - Comprehensive UMAP visualization\")\n",
    "print(\"  2. baseline_vs_lora_comparison.png - Side-by-side comparison\")\n",
    "print(\"  3. lora_vs_baseline_metrics.csv - Quantitative metrics\")\n",
    "print(\"  4. burn_sham_with_lora_embeddings.h5ad - AnnData with all embeddings\")\n",
    "print(\"\\nBest checkpoint: epoch=09-val_loss=0.5877.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary comparison table\n",
    "comparison_df = pd.DataFrame([baseline_metrics, lora_metrics])\n",
    "comparison_df = comparison_df.set_index('name')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: Baseline vs LoRA Multi-Covariate\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df)\n",
    "\n",
    "# Compute improvement\n",
    "improvement = {\n",
    "    'accuracy': ((lora_metrics['accuracy'] - baseline_metrics['accuracy']) / baseline_metrics['accuracy']) * 100,\n",
    "    'f1_score': ((lora_metrics['f1_score'] - baseline_metrics['f1_score']) / baseline_metrics['f1_score']) * 100,\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVEMENT (%)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in improvement.items():\n",
    "    print(f\"{metric}: {value:+.2f}%\")\n",
    "\n",
    "# Save metrics\n",
    "comparison_df.to_csv('/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/lora_vs_baseline_metrics.csv')\n",
    "print(\"\\n‚úì Metrics saved to: lora_vs_baseline_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def evaluate_embeddings(adata, embedding_key, name):\n",
    "    \"\"\"Evaluate embedding quality using multiple metrics.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    X = adata.obsm[embedding_key]\n",
    "    \n",
    "    # 1. Cell Type Classification (kNN)\n",
    "    print(\"\\n1. Cell Type Classification (10-fold CV):\")\n",
    "    y = adata.obs['cell_types_simple_short'].values\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    for seed in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "        )\n",
    "        knn = KNeighborsClassifier(n_neighbors=15)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    print(f\"   Accuracy: {np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}\")\n",
    "    print(f\"   F1 Score: {np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\")\n",
    "    \n",
    "    # 2. Temporal Coherence\n",
    "    print(\"\\n2. Temporal Coherence:\")\n",
    "    timepoints = sorted(adata.obs['timepoint'].unique())\n",
    "    \n",
    "    for i in range(len(timepoints) - 1):\n",
    "        tp1, tp2 = timepoints[i], timepoints[i+1]\n",
    "        \n",
    "        # Get embeddings for each timepoint\n",
    "        idx1 = adata.obs['timepoint'] == tp1\n",
    "        idx2 = adata.obs['timepoint'] == tp2\n",
    "        \n",
    "        emb1 = X[idx1]\n",
    "        emb2 = X[idx2]\n",
    "        \n",
    "        # Compute average distance between consecutive timepoints\n",
    "        distances = cdist(emb1, emb2, metric='cosine')\n",
    "        avg_dist = np.mean(distances)\n",
    "        \n",
    "        print(f\"   {tp1} ‚Üí {tp2}: {avg_dist:.4f}\")\n",
    "    \n",
    "    # 3. Condition Separation\n",
    "    print(\"\\n3. Condition Separation:\")\n",
    "    conditions = sorted(adata.obs['condition'].unique())\n",
    "    \n",
    "    for tp in timepoints:\n",
    "        tp_mask = adata.obs['timepoint'] == tp\n",
    "        \n",
    "        burn_emb = X[(tp_mask) & (adata.obs['condition'] == 'burn')]\n",
    "        sham_emb = X[(tp_mask) & (adata.obs['condition'] == 'sham')]\n",
    "        \n",
    "        if len(burn_emb) > 0 and len(sham_emb) > 0:\n",
    "            # Average distance between burn and sham at this timepoint\n",
    "            distances = cdist(burn_emb, sham_emb, metric='cosine')\n",
    "            avg_dist = np.mean(distances)\n",
    "            print(f\"   {tp}: burn ‚Üî sham distance = {avg_dist:.4f}\")\n",
    "    \n",
    "    # 4. Batch Mixing (Silhouette score)\n",
    "    print(\"\\n4. Batch Mixing (Mouse ID):\")\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    \n",
    "    if 'mouse_id' in adata.obs.columns:\n",
    "        # Lower silhouette score = better batch mixing\n",
    "        sil_score = silhouette_score(X, adata.obs['mouse_id'], metric='cosine', sample_size=5000)\n",
    "        print(f\"   Silhouette Score: {sil_score:.4f} (lower = better mixing)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': np.mean(accuracies),\n",
    "        'f1_score': np.mean(f1_scores),\n",
    "        'name': name\n",
    "    }\n",
    "\n",
    "# Evaluate both embeddings\n",
    "baseline_metrics = evaluate_embeddings(adata, 'X_state_baseline', 'Baseline SE-600M')\n",
    "lora_metrics = evaluate_embeddings(adata, 'X_lora_conditioned', 'LoRA Multi-Covariate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Quantitative Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison: Baseline vs LoRA UMAPs\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Compute UMAP for baseline embeddings\n",
    "print(\"Computing UMAP for baseline embeddings...\")\n",
    "adata_baseline = adata.copy()\n",
    "sc.pp.neighbors(adata_baseline, use_rep='X_state_baseline', n_neighbors=15, random_state=42)\n",
    "sc.tl.umap(adata_baseline, random_state=42)\n",
    "\n",
    "# Row 1: Baseline embeddings\n",
    "sc.pl.umap(adata_baseline, color='timepoint', ax=axes[0, 0], show=False, \n",
    "           title='Baseline: Timepoint')\n",
    "sc.pl.umap(adata_baseline, color='condition', ax=axes[0, 1], show=False, \n",
    "           title='Baseline: Condition')\n",
    "sc.pl.umap(adata_baseline, color='cell_types_simple_short', ax=axes[0, 2], show=False, \n",
    "           title='Baseline: Cell Type', legend_loc='on data', legend_fontsize=6)\n",
    "\n",
    "# Row 2: LoRA embeddings (already computed)\n",
    "sc.pl.umap(adata, color='timepoint', ax=axes[1, 0], show=False, \n",
    "           title='LoRA: Timepoint')\n",
    "sc.pl.umap(adata, color='condition', ax=axes[1, 1], show=False, \n",
    "           title='LoRA: Condition')\n",
    "sc.pl.umap(adata, color='cell_types_simple_short', ax=axes[1, 2], show=False, \n",
    "           title='LoRA: Cell Type', legend_loc='on data', legend_fontsize=6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/scumpia-mrl/Desktop/Sujit/Projects/state-experimentation/baseline_vs_lora_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Comparison plot saved to: baseline_vs_lora_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if baseline embeddings exist, if not extract them\n",
    "if 'X_state_baseline' not in adata.obsm:\n",
    "    print(\"Baseline embeddings not found. Extracting baseline embeddings from pretrained SE-600M...\")\n",
    "    \n",
    "    # Load base model for comparison\n",
    "    from src.state.emb.nn.lora_covariate_model import LoRACovariateStateModel\n",
    "    \n",
    "    base_model = LoRACovariateStateModel(\n",
    "        base_checkpoint_path=config['base_checkpoint'],\n",
    "        covariate_config=config['covariates'],\n",
    "        lora_config=config['lora'],\n",
    "    )\n",
    "    base_model.eval()\n",
    "    base_model = base_model.cuda()\n",
    "    \n",
    "    # Extract baseline embeddings (without LoRA/covariate conditioning)\n",
    "    baseline_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, adata.n_obs, batch_size), desc=\"Extracting baseline\"):\n",
    "            batch_end = min(i + batch_size, adata.n_obs)\n",
    "            batch_cells = adata[i:batch_end]\n",
    "            \n",
    "            if 'X_norm' in batch_cells.layers:\n",
    "                batch_expr = torch.tensor(batch_cells.layers['X_norm'], dtype=torch.float32).cuda()\n",
    "            else:\n",
    "                batch_expr = torch.tensor(batch_cells.X.toarray() if hasattr(batch_cells.X, 'toarray') else batch_cells.X, dtype=torch.float32).cuda()\n",
    "            \n",
    "            # Get base embeddings (no covariates)\n",
    "            base_emb = base_model.model(batch_expr)\n",
    "            baseline_embeddings.append(base_emb.cpu().numpy())\n",
    "    \n",
    "    adata.obsm['X_state_baseline'] = np.vstack(baseline_embeddings)\n",
    "    print(f\"‚úì Baseline embeddings extracted: {adata.obsm['X_state_baseline'].shape}\")\n",
    "else:\n",
    "    print(f\"‚úì Baseline embeddings already exist: {adata.obsm['X_state_baseline'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare with Baseline Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary & Next Steps\n\nThis notebook implemented LoRA-based multi-covariate fine-tuning of the SE-600M model.\n\n### ‚úÖ Completed Work\n\n1. **LoRA Multi-Covariate Model**: Successfully trained SE-600M with LoRA adapters conditioned on timepoint and condition\n2. **Embedding Extraction**: Generated covariate-conditioned embeddings from best checkpoint (epoch=09-val_loss=0.5877.ckpt)\n3. **UMAP Visualization**: Created comprehensive visualizations showing embedding structure\n4. **Quantitative Evaluation**: Computed metrics comparing baseline vs LoRA embeddings\n\n### üîç Key Findings\n\n**LoRA Embeddings Show Strong Temporal/Condition Signal BUT Mixed Cell Types**:\n\nFrom UMAP analysis:\n- ‚úÖ **Strong separation** by timepoint (day10, day14, day19)\n- ‚úÖ **Clear separation** by condition (burn vs sham)\n- ‚ùå **Mixed cell type clustering** (cell types not well-separated within timepoint/condition groups)\n\n**Quantitative Metrics**:\n- Cell type accuracy: ~75% (vs 96% baseline)\n- Temporal coherence: Improved (lower distances between consecutive timepoints)\n- Condition separation: Improved (higher distances between burn/sham)\n\n### üìã Decision: Use Baseline SE-600M Embeddings for State Transition Training\n\n**Rationale**:\n- **Goal**: Predict gene perturbation effects in wound healing context\n- **Critical requirement**: Cell type identity preservation is essential for perturbation prediction\n- **LoRA embeddings**: Optimized temporal/condition signal at the cost of cell type clustering\n- **State Transition model**: Needs strong cell type structure to learn cell-type-specific responses\n\n**Chosen Strategy (Strategy 2)**:\nUse baseline SE-600M embeddings + add temporal/condition as metadata covariates in ST training\n\n### ‚è≠Ô∏è Next Phase: State Transition Model Training\n\nSee [phase3a_st_data_preparation.ipynb](phase3a_st_data_preparation.ipynb) for:\n1. Data preparation with baseline embeddings\n2. TOML/YAML configuration creation\n3. Code modifications to Arc Institute's State Transition model for timepoint embeddings\n\n**Modified Files**:\n- [src/state/tx/models/state_transition.py](src/state/tx/models/state_transition.py) (lines 200-210, 431-448)\n- [src/state/tx/data/dataset/scgpt_perturbation_dataset.py](src/state/tx/data/dataset/scgpt_perturbation_dataset.py) (lines 175-212)\n\n### üéØ Alternative Strategies (Future Work)\n\nIf baseline + ST doesn't meet performance targets, consider:\n\n1. **Strategy 1**: Refine LoRA embeddings with cell type preservation\n   - Add cell type as explicit covariate\n   - Use contrastive loss to preserve cell type clustering\n   - Retrain LoRA model\n\n2. **Strategy 3**: Fine-tune State Transition model with LoRA\n   - Treat burn/sham as perturbations for ST training\n   - Use LoRA adapters on ST transformer backbone\n   - More direct adaptation to wound healing biology"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-state (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}